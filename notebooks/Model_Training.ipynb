{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 2: Model Training - Fraud Detection\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths based on project structure\n",
    "data_path = \"../data/processed/\"\n",
    "models_path = \"../models/\"\n",
    "reports_path = \"../reports/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "os.makedirs(reports_path, exist_ok=True)\n",
    "\n",
    "# ðŸ“Œ Load Processed Fraud Data\n",
    "fraud_data_path = os.path.join(data_path, \"processed_fraud_data.csv\")\n",
    "fraud_data = pd.read_csv(fraud_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ“Œ Drop Non-Numeric Columns\n",
    "drop_columns = [\"user_id\", \"device_id\", \"sex\"]  # Remove unnecessary text columns\n",
    "fraud_data = fraud_data.drop(columns=drop_columns)\n",
    "\n",
    "# ðŸ“Œ Convert Datetime Columns to Unix Timestamps\n",
    "datetime_columns = [\"signup_time\", \"purchase_time\"]\n",
    "for col in datetime_columns:\n",
    "    fraud_data[col] = pd.to_datetime(fraud_data[col], errors=\"coerce\").astype(int) // 10**9\n",
    "\n",
    "# ðŸ“Œ Define Features (X) and Target (y)\n",
    "feature_columns = [\"signup_time\", \"purchase_time\", \"purchase_value\", \"source\", \"browser\", \"age\",\n",
    "                   \"ip_address\", \"country\", \"transaction_delay\", \"hour_of_day\", \"day_of_week\"]\n",
    "X_fraud = fraud_data[feature_columns]  # Features\n",
    "y_fraud = fraud_data[\"class\"]  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Data Types:\n",
      " signup_time            int64\n",
      "purchase_time          int64\n",
      "purchase_value       float64\n",
      "source                 int64\n",
      "browser                int64\n",
      "age                    int64\n",
      "ip_address           float64\n",
      "country                int64\n",
      "transaction_delay    float64\n",
      "hour_of_day            int64\n",
      "day_of_week            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ðŸ“Œ Train-Test Split\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(\n",
    "    X_fraud, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
    ")\n",
    "\n",
    "# ðŸ“Œ Verify Data Types (Ensure all columns are numeric)\n",
    "print(\"Feature Data Types:\\n\", X_fraud_train.dtypes)\n",
    "\n",
    "# ðŸ“Œ Define Models for Fraud Detection\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"MLP Classifier\": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training Gradient Boosting...\n",
      "Training MLP Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Train and Evaluate Models\n",
    "model_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_fraud_train, y_fraud_train)\n",
    "    y_pred = model.predict(X_fraud_test)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(y_fraud_test, y_pred)\n",
    "    precision = precision_score(y_fraud_test, y_pred)\n",
    "    recall = recall_score(y_fraud_test, y_pred)\n",
    "    f1 = f1_score(y_fraud_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_fraud_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    model_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC-AUC\": roc_auc\n",
    "    })\n",
    "\n",
    "    # Save the trained model\n",
    "    model_filename = f\"{name.replace(' ', '_')}.pkl\"\n",
    "    joblib.dump(model, os.path.join(models_path, model_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Model Training Complete!\n",
      "ðŸ“‚ Trained models saved in: ../models/\n",
      "ðŸ“‚ Evaluation report saved in: ../reports/model_performance.csv\n",
      "ðŸ“Š Model Performance Results:\n",
      "                  Model  Accuracy  Precision    Recall  F1 Score   ROC-AUC\n",
      "0  Logistic Regression  0.906363   0.000000  0.000000  0.000000  0.500000\n",
      "1        Decision Tree  0.907885   0.507367  0.559717  0.532258  0.751786\n",
      "2        Random Forest  0.955696   1.000000  0.526855  0.690118  0.763428\n",
      "3    Gradient Boosting  0.955696   1.000000  0.526855  0.690118  0.763428\n",
      "4       MLP Classifier  0.906363   0.000000  0.000000  0.000000  0.500000\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Convert results to DataFrame\n",
    "results_df = pd.DataFrame(model_results)\n",
    "\n",
    "# Save evaluation results\n",
    "results_file = os.path.join(reports_path, \"model_performance.csv\")\n",
    "results_df.to_csv(results_file, index=False)\n",
    "\n",
    "# Display results using Pandas\n",
    "print(\"\\nâœ… Model Training Complete!\")\n",
    "print(\"ðŸ“‚ Trained models saved in:\", models_path)\n",
    "print(\"ðŸ“‚ Evaluation report saved in:\", results_file)\n",
    "print(\"ðŸ“Š Model Performance Results:\\n\", results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature list saved in trained_features.txt\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Save the feature names used during training\n",
    "feature_file = os.path.join(models_path, \"trained_features.txt\")\n",
    "\n",
    "with open(feature_file, \"w\") as f:\n",
    "    for feature in X_fraud_train.columns:\n",
    "        f.write(feature + \"\\n\")\n",
    "\n",
    "print(\"âœ… Feature list saved in trained_features.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-jkyell",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed datasets\n",
    "fraud_data_path = \"../data/processed_fraud_data.csv\"\n",
    "creditcard_data_path = \"../data/creditcard.csv\"\n",
    "\n",
    "fraud_data = pd.read_csv(fraud_data_path)\n",
    "creditcard_data = pd.read_csv(creditcard_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud_Data.csv (E-commerce transactions)\n",
    "X_fraud = fraud_data.drop(columns=[\"class\"])  # Features\n",
    "y_fraud = fraud_data[\"class\"]  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creditcard.csv (Bank transactions)\n",
    "X_creditcard = creditcard_data.drop(columns=[\"Class\"])  # Features\n",
    "y_creditcard = creditcard_data[\"Class\"]  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(\n",
    "    X_fraud, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
    ")\n",
    "\n",
    "X_credit_train, X_credit_test, y_credit_train, y_credit_test = train_test_split(\n",
    "    X_creditcard, y_creditcard, test_size=0.2, random_state=42, stratify=y_creditcard\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data Preparation Complete! Processed train-test datasets saved in 'data/processed/'.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Step 1: Data Preparation for Model Training\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "import os\n",
    "\n",
    "# Load the processed datasets\n",
    "fraud_data_path = \"../data/processed_fraud_data.csv\"\n",
    "creditcard_data_path = \"../data/creditcard.csv\"\n",
    "\n",
    "fraud_data = pd.read_csv(fraud_data_path)\n",
    "creditcard_data = pd.read_csv(creditcard_data_path)\n",
    "\n",
    "# ðŸ“Œ Separate Features (X) and Target Variable (y)\n",
    "\n",
    "# Fraud_Data.csv (E-commerce transactions)\n",
    "X_fraud = fraud_data.drop(columns=[\"class\"])  # Features\n",
    "y_fraud = fraud_data[\"class\"]  # Target\n",
    "\n",
    "# Creditcard.csv (Bank transactions)\n",
    "X_creditcard = creditcard_data.drop(columns=[\"Class\"])  # Features\n",
    "y_creditcard = creditcard_data[\"Class\"]  # Target\n",
    "\n",
    "# ðŸ“Œ Convert Datetime Columns into Unix Timestamp\n",
    "datetime_columns = [\"signup_time\", \"purchase_time\"]\n",
    "for col in datetime_columns:\n",
    "    if col in X_fraud.columns:\n",
    "        X_fraud[col] = pd.to_datetime(X_fraud[col]).astype(int) // 10**9\n",
    "\n",
    "# ðŸ“Œ Perform Train-Test Split (80% Training, 20% Testing)\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(\n",
    "    X_fraud, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
    ")\n",
    "\n",
    "X_credit_train, X_credit_test, y_credit_train, y_credit_test = train_test_split(\n",
    "    X_creditcard, y_creditcard, test_size=0.2, random_state=42, stratify=y_creditcard\n",
    ")\n",
    "\n",
    "# ðŸ“Œ Encode Categorical Variables Using OrdinalEncoder\n",
    "categorical_columns = [\"browser\", \"source\", \"country\"]\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "# Apply encoding only to categorical columns in Fraud Data\n",
    "X_fraud_train[categorical_columns] = ordinal_encoder.fit_transform(X_fraud_train[categorical_columns])\n",
    "X_fraud_test[categorical_columns] = ordinal_encoder.transform(X_fraud_test[categorical_columns])\n",
    "\n",
    "# ðŸ“Œ Normalize Numerical Features Using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Select only numerical columns\n",
    "numeric_columns = X_fraud_train.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "X_fraud_train_scaled = pd.DataFrame(scaler.fit_transform(X_fraud_train[numeric_columns]), columns=numeric_columns)\n",
    "X_fraud_test_scaled = pd.DataFrame(scaler.transform(X_fraud_test[numeric_columns]), columns=numeric_columns)\n",
    "\n",
    "# Ensure categorical features are added back after scaling\n",
    "for col in categorical_columns:\n",
    "    X_fraud_train_scaled[col] = X_fraud_train[col].values\n",
    "    X_fraud_test_scaled[col] = X_fraud_test[col].values\n",
    "\n",
    "# ðŸ“Œ Save Processed Train-Test Datasets\n",
    "processed_data_path = \"../data/processed/\"\n",
    "\n",
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)\n",
    "\n",
    "X_fraud_train_scaled.to_csv(f\"{processed_data_path}X_fraud_train.csv\", index=False)\n",
    "X_fraud_test_scaled.to_csv(f\"{processed_data_path}X_fraud_test.csv\", index=False)\n",
    "y_fraud_train.to_csv(f\"{processed_data_path}y_fraud_train.csv\", index=False)\n",
    "y_fraud_test.to_csv(f\"{processed_data_path}y_fraud_test.csv\", index=False)\n",
    "\n",
    "X_credit_train.to_csv(f\"{processed_data_path}X_credit_train.csv\", index=False)\n",
    "X_credit_test.to_csv(f\"{processed_data_path}X_credit_test.csv\", index=False)\n",
    "y_credit_train.to_csv(f\"{processed_data_path}y_credit_train.csv\", index=False)\n",
    "y_credit_test.to_csv(f\"{processed_data_path}y_credit_test.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Data Preparation Complete! Processed train-test datasets saved in 'data/processed/'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Save Processed Train-Test Datasets\n",
    "processed_data_path = \"../data/processed/\"\n",
    "\n",
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)\n",
    "\n",
    "X_fraud_train_scaled.to_csv(f\"{processed_data_path}X_fraud_train.csv\", index=False)\n",
    "X_fraud_test_scaled.to_csv(f\"{processed_data_path}X_fraud_test.csv\", index=False)\n",
    "y_fraud_train.to_csv(f\"{processed_data_path}y_fraud_train.csv\", index=False)\n",
    "y_fraud_test.to_csv(f\"{processed_data_path}y_fraud_test.csv\", index=False)\n",
    "\n",
    "X_credit_train_scaled.to_csv(f\"{processed_data_path}X_credit_train.csv\", index=False)\n",
    "X_credit_test_scaled.to_csv(f\"{processed_data_path}X_credit_test.csv\", index=False)\n",
    "y_credit_train.to_csv(f\"{processed_data_path}y_credit_train.csv\", index=False)\n",
    "y_credit_test.to_csv(f\"{processed_data_path}y_credit_test.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Data Preparation Complete! Processed train-test datasets saved in 'data/processed/'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
